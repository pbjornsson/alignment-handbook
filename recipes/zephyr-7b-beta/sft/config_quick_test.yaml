
# Quick test config for Colab T4 GPU
# Trains in ~5-10 minutes
# Perfect for testing the training pipeline without waiting hours

# Model arguments
model_name_or_path: HuggingFaceTB/SmolLM2-360M-Instruct  # Small but capable model
torch_dtype: bfloat16

# Data arguments
dataset_mixture:
  datasets:
    - id: HuggingFaceH4/ultrachat_200k
      split: train_sft
      weight: 0.005  # 0.5% of data (~1000 examples)
preprocessing_num_workers: 2

# Training arguments
output_dir: /content/drive/MyDrive/alignment-handbook/quick-test
max_steps: 100  # Just 100 steps for quick test
per_device_train_batch_size: 2
gradient_accumulation_steps: 4  # Effective batch size = 8
learning_rate: 2.0e-04
warmup_steps: 10
logging_steps: 5
save_steps: 50  # Save checkpoint at step 50
save_total_limit: 2  # Keep only 2 checkpoints to save space
bf16: true
gradient_checkpointing: true
do_eval: true
eval_strategy: steps
eval_steps: 50
report_to:
  - tensorboard

# Push to hub (optional - set to true if you want to share)
push_to_hub: false
hub_model_id: my-quick-test-model  # Change this if you enable push_to_hub
